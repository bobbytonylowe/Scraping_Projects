{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_links(hashtag):\n",
    "\n",
    "    '''Code to return url pages where a hashtag has been used'''\n",
    "    \n",
    "    #####CHANGE#### - This is the location of chromedriver on my computer\n",
    "    chromedriver = \"C:/webdrivers/chromedriver\"\n",
    "    browser = webdriver.Chrome(chromedriver)\n",
    "    \n",
    "    #Opens the instgram tags pages and searches the hashtag\n",
    "    browser.get('https://www.instagram.com/explore/tags/'+hashtag)\n",
    "    Pagelength = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight/1.5);\")\n",
    "    links=[]\n",
    "    source = browser.page_source\n",
    "    data=bs(source, 'html.parser')\n",
    "    body = data.find('body')\n",
    "    script = body.find('span')\n",
    "    for link in script.findAll('a'):\n",
    "         if re.match(\"/p\", link.get('href')):\n",
    "             links.append('https://www.instagram.com'+link.get('href'))\n",
    "            \n",
    "    #sleep time is required. If you don't use this Instagram may interrupt the script and doesn't scroll through pages\n",
    "    time.sleep(5) \n",
    "    Pagelength = browser.execute_script(\"window.scrollTo(document.body.scrollHeight/1.5, document.body.scrollHeight/3.0);\")\n",
    "    source = browser.page_source\n",
    "    data=bs(source, 'html.parser')\n",
    "    body = data.find('body')\n",
    "    script = body.find('span')\n",
    "    for link in script.findAll('a'):\n",
    "         if re.match(\"/p\", link.get('href')):\n",
    "                links.append('https://www.instagram.com'+link.get('href'))\n",
    "\n",
    "    # Create a zipped list of tuples from above lists\n",
    "    zippedList =  list(zip(links))\n",
    "\n",
    "    # Create a dataframe from zipped list\n",
    "    dfObj = pd.DataFrame(zippedList, columns = ['Url_links']) \n",
    "    dfObj.to_csv('hashtag_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to scrape the information from one user\n",
    "def recent_posts(username, number):\n",
    "    \n",
    "    # number = how many posts you want a url for \n",
    "    \n",
    "    \"\"\"With the input of an account page, scrape the 'number' of most recent posts urls\"\"\"\n",
    "        \n",
    "    #####CHANGE#### - This is the location of chromedriver on my computer\n",
    "    chromedriver = \"C:/webdrivers/chromedriver\"\n",
    "    browser = webdriver.Chrome(chromedriver)\n",
    "    \n",
    "    #define url\n",
    "    url = \"https://www.instagram.com/\" + username + \"/\"\n",
    "    \n",
    "    #use chrome to launch url\n",
    "    browser.get(url)\n",
    "    post = 'https://www.instagram.com/p/'\n",
    "    \n",
    "    post_links = []\n",
    "    \n",
    "    while len(post_links) < number:\n",
    "        links = [a.get_attribute('href') for a in browser.find_elements_by_tag_name('a')]\n",
    "        for link in links:\n",
    "            if post in link and link not in post_links:\n",
    "                post_links.append(link)\n",
    "        scroll_down = \"window.scrollTo(0, document.body.scrollHeight);\"\n",
    "        browser.execute_script(scroll_down)\n",
    "        time.sleep(10)\n",
    "    else:\n",
    "        # Create a zipped list of tuples from above lists\n",
    "        zippedList =  list(zip(post_links))\n",
    "\n",
    "        # Create a dataframe from zipped list\n",
    "        dfObj = pd.DataFrame(zippedList, columns = ['Url_links']) \n",
    "        \n",
    "        \n",
    "        return dfObj.to_csv('user_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_posts('bobbytonylowe', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instagram_crawler(base_url):\n",
    "    chromedriver = \"C:/webdrivers/chromedriver\"\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    actions = ActionChains(driver)\n",
    "\n",
    "    driver.get(base_url)\n",
    "    Pagelength = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight/1.5);\")\n",
    "\n",
    "    images = driver.find_elements_by_class_name(\"_bz0w\")\n",
    "    #image_curr = images[0].find_element_by_tag_name(\"a\").get_attribute(\"href\")\n",
    "    #driver.get(image_curr) #go to first picture\n",
    "\n",
    "    comments = driver.find_elements_by_class_name(\"C4VMK\")\n",
    "\n",
    "    comments_list, users_list = [], []\n",
    "\n",
    "    for c in comments:\n",
    "        comment = c.find_element_by_css_selector('span').get_attribute(\"textContent\")\n",
    "        user = c.find_element_by_class_name(\"TlrDj\").get_attribute(\"textContent\")\n",
    "        \n",
    "        #print(\"\" + user + \": \" + str(comment))\n",
    "        comments_list.append(comment)\n",
    "        users_list.append(user)\n",
    "   \n",
    "\n",
    "    #sleep time is required. If you don't use this Instagram may interrupt the script and doesn't scroll through pages\n",
    "    time.sleep(5) \n",
    "        \n",
    "    df = pd.DataFrame({\"user\": users_list, \"comment\": comments_list})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>motorsport.video</td>\n",
       "      <td>Indycar is a great series for racing fansðŸ”¥Is i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>israelmorrison</td>\n",
       "      <td>The machines are coming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pivotles</td>\n",
       "      <td>None of these guys could hang in F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rubencitymadhouse14</td>\n",
       "      <td>Just like an F1 race thereâ€™s no contest, Indyc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sahil_chandnani98</td>\n",
       "      <td>Best part is that there are a lot of cars on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>raymarshjr</td>\n",
       "      <td>Most definitely....better competition in Indyc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kevinscarz</td>\n",
       "      <td>In terms of pure racing Indycar is superior be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kyyyyyhan</td>\n",
       "      <td>Nothing better than F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>franciscosta_4327</td>\n",
       "      <td>Y E S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wentidizi</td>\n",
       "      <td>No!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cyrus_555</td>\n",
       "      <td>I was at the live race and I was at the last turn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>manlikecamf1</td>\n",
       "      <td>Was just waiting for a pile up into turn 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>james__appleton</td>\n",
       "      <td>Not better than F1.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user                                            comment\n",
       "0      motorsport.video  Indycar is a great series for racing fansðŸ”¥Is i...\n",
       "1        israelmorrison                            The machines are coming\n",
       "2              pivotles                None of these guys could hang in F1\n",
       "3   rubencitymadhouse14  Just like an F1 race thereâ€™s no contest, Indyc...\n",
       "4     sahil_chandnani98  Best part is that there are a lot of cars on t...\n",
       "5            raymarshjr  Most definitely....better competition in Indyc...\n",
       "6            kevinscarz  In terms of pure racing Indycar is superior be...\n",
       "7             kyyyyyhan                             Nothing better than F1\n",
       "8     franciscosta_4327                                              Y E S\n",
       "9             wentidizi                                                No!\n",
       "10            cyrus_555  I was at the live race and I was at the last turn\n",
       "11         manlikecamf1         Was just waiting for a pile up into turn 1\n",
       "12      james__appleton                                Not better than F1."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instagram_crawler(\"https://www.instagram.com/p/B08-mLEnNR8/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create an excel file with multiple sheets\n",
    "def dfs_tabs(df_list, sheet_list, file_name):\n",
    "    \n",
    "    '''function to create an excel file with multiple sheets '''\n",
    "    \n",
    "    writer = pd.ExcelWriter(file_name,engine='xlsxwriter')   \n",
    "\n",
    "    for dataframe, sheet in zip(df_list, sheet_list):\n",
    "        dataframe.to_excel(writer, sheet_name=sheet, startrow=0 , startcol=0)   \n",
    "        \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(url):\n",
    "    \n",
    "    try:    \n",
    "        html = urllib.request.urlopen(url)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        data = soup.find_all('meta', attrs={'property': 'og:description'\n",
    "                             })\n",
    "        text = data[0].get('content').split()\n",
    "        user = '%s %s %s' % (text[-3], text[-2], text[-1])\n",
    "        followers = text[0]\n",
    "        following = text[2]\n",
    "        posts = text[4]\n",
    "        return user[0:18]\n",
    "    except:\n",
    "        pass\n",
    "        return 'unknown'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bobby Lowe (@bobby'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name('https://www.instagram.com/bobbytonylowe/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Bobby Lowe (@bobbytonylowe)\n",
      "Followers: 407\n",
      "Following: 706\n",
      "Posts: 192\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "def getprofile(url):\n",
    "    html = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    data = soup.find_all('meta', attrs={'property': 'og:description'\n",
    "                         })\n",
    "    text = data[0].get('content').split()\n",
    "    user = '%s %s %s' % (text[-3], text[-2], text[-1])\n",
    "    followers = text[0]\n",
    "    following = text[2]\n",
    "    posts = text[4]\n",
    "    print ('User:', user)\n",
    "    print ('Followers:', followers)\n",
    "    print ('Following:', following)\n",
    "    print ('Posts:', posts)\n",
    "    print ('---------------------------')\n",
    "getprofile(\"https://www.instagram.com/bobbytonylowe/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the url links\n",
    "df =  pd.read_csv('hashtag_links.csv')\n",
    "df = df['hashtags']\n",
    "page_list = list(str(e) for e in df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of each instgram user for each of the instgram posts\n",
    "sheet_name = [get_name(x) for x in page_list]\n",
    "\n",
    "#List comprehension to create a list of dataframes created from the instagram crawler function \n",
    "dfs = [instagram_crawler(x) for x in page_list]\n",
    "\n",
    "#Perform the multiple excel sheet function on the selected dataframes\n",
    "dfs_tabs(dfs, sheet_name, 'instagram_comments.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
